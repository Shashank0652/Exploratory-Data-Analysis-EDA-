{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70752c4",
   "metadata": {},
   "source": [
    " Q1. Importing Libraries and Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5450d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('Customer Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd60b544",
   "metadata": {},
   "source": [
    "Q2. Overview of Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79050d-fd12-41dc-b325-d178080c0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7105cf-86ba-4d98-861e-256c87047bf5",
   "metadata": {},
   "source": [
    "Q3. Check for duplicate values in the 'customerID' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78d626-26f6-4413-b767-32b4ce55638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Check for duplicate values in the 'customerID' column\n",
    "duplicate_customer_ids = df[\"customerID\"].duplicated().sum()\n",
    "print(f\"Total duplicate customer IDs: {duplicate_customer_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04bd525",
   "metadata": {},
   "source": [
    "Q4. Checking for Missing Values in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07062b-d7d5-4390-9008-8eaaead5430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396f029",
   "metadata": {},
   "source": [
    "Q5. Statistical Summary of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d681f51-b1d6-4afe-8171-7c466d3b6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70785b4",
   "metadata": {},
   "source": [
    "Q6. Checking for Duplicate Customer IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8c72f-86c7-4fec-abea-7b356c2b417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"customerID\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e677f97",
   "metadata": {},
   "source": [
    "Q7. converted 0 and 1 values of senior citizen to yes/no to make it easier to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044acb3b-cd92-474c-bd3e-b03f96316536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(value):\n",
    "    if value == 1:\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "df['SeniorCitizen'] = df[\"SeniorCitizen\"].apply(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1edae",
   "metadata": {},
   "source": [
    "Q8. Visualizing Customer Churn Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007056d4-0eef-485c-923e-e3243031e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x = 'Churn', data = df)\n",
    "\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title(\"Count of Customers by Churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173cb15",
   "metadata": {},
   "source": [
    "Q9. from the given pie chart we can conclude that 26.54% of our customers have churned out. \n",
    "#not let's explore the reason behind it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2c132-3121-4189-962d-2517ebe1fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3,4))\n",
    "gb = df.groupby(\"Churn\").agg({'Churn':\"count\"})\n",
    "plt.pie(gb['Churn'], labels = gb.index, autopct = \"%1.2f%%\")\n",
    "plt.title(\"Percentage of Churned Customeres\", fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb6bbb",
   "metadata": {},
   "source": [
    "Q10.Churn Distribution by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f483a8e-21c2-41d5-a054-dc2e2931e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3,3))\n",
    "sns.countplot(x = \"gender\", data = df, hue = \"Churn\")\n",
    "plt.title(\"Churn by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f1e84f",
   "metadata": {},
   "source": [
    "Q11. Count of Customers by Senior Citizen Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f91301-a8ca-483c-a689-2852691495f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4,4))\n",
    "ax = sns.countplot(x = \"SeniorCitizen\", data = df)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title(\"Count of Customers by Senior Citizen\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e4c31c",
   "metadata": {},
   "source": [
    "Q12. comparative a greater pecentage of people in senior citizen category have churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24784c2d-2e11-40fe-9519-2b4e515ffc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df.groupby('SeniorCitizen')['Churn'].value_counts(normalize=True).unstack() * 100\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(4, 4))  # Adjust figsize for better visualization\n",
    "\n",
    "# Plot the bars\n",
    "total_counts.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#ff7f0e'])  # Customize colors if desired\n",
    "\n",
    "# Add percentage labels on the bars\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
    "\n",
    "plt.title('Churn by Senior Citizen (Stacked Bar Chart)')\n",
    "plt.xlabel('SeniorCitizen')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Churn', bbox_to_anchor = (0.9,0.9))  # Customize legend location\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac316cd",
   "metadata": {},
   "source": [
    "Q13. people who have used our services for a long time have stayed and people who have used our sevices \n",
    "#1 or 2 months  have churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545e7a1-b155-4768-b280-339cbd4e4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9,4))\n",
    "sns.histplot(x = \"tenure\", data = df, bins = 72, hue = \"Churn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea65523",
   "metadata": {},
   "source": [
    "Q14.people who have month to month contract are likely to churn then from those who have 1 or 2 years or contract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5934bc-eb9d-4a93-9216-2d441a557cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4,4))\n",
    "ax = sns.countplot(x = \"Contract\", data = df, hue = \"Churn\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title(\"Count of Customers by Contract\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf28fd",
   "metadata": {},
   "source": [
    "Q15. Displaying Column Names of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e38c5-0a86-4143-a9da-9e45b3e6c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537f941",
   "metadata": {},
   "source": [
    "Q16. The majority of customers who do not churn tend to have services like PhoneService, InternetService (particularly DSL), and OnlineSecurity enabled. For services like OnlineBackup, TechSupport, and StreamingTV, churn rates are noticeably higher when these services are not used or are unavailable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82f8bf-25a4-4df5-98a0-5736406b107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', \n",
    "           'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "# Number of columns for the subplot grid (you can change this)\n",
    "n_cols = 3\n",
    "n_rows = (len(columns) + n_cols - 1) // n_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))  # Adjust figsize as needed\n",
    "\n",
    "# Flatten the axes array for easy iteration (handles both 1D and 2D arrays)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over columns and plot count plots\n",
    "for i, col in enumerate(columns):\n",
    "    sns.countplot(x=col, data=df, ax=axes[i], hue = df[\"Churn\"])\n",
    "    axes[i].set_title(f'Count Plot of {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Remove empty subplots (if any)\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bc353",
   "metadata": {},
   "source": [
    "Q17. customer is likely to churn when he is using electronic check as a payment method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3a8d4-1866-47b2-bdd2-bb793bc4637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,4))\n",
    "ax = sns.countplot(x = \"PaymentMethod\", data = df, hue = \"Churn\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.bar_label(ax.containers[1])\n",
    "plt.title(\"Churned Customers by Payment Method\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3c35f",
   "metadata": {},
   "source": [
    "Q18.We can now check whether the model is effectively predicting churn based on the payment method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d559f2d-1f25-451c-8f1d-997f29766e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1. Load the dataset (For demonstration, we'll create a sample dataset)\n",
    "data = {\n",
    "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'payment_method': ['Electronic check', 'Credit card', 'Bank transfer', 'Electronic check', 'Credit card',\n",
    "                       'Electronic check', 'Bank transfer', 'Electronic check', 'Credit card', 'Bank transfer'],\n",
    "    'churn': [1, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
    "}\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "# We will create a new column to check if the customer is using an Electronic check as payment method.\n",
    "df['electronic_check'] = np.where(df['payment_method'] == 'Electronic check', 1, 0)\n",
    "\n",
    "# Check the data\n",
    "print(df)\n",
    "\n",
    "# 3. Feature Engineering\n",
    "# Define features (X) and target (y)\n",
    "X = df[['electronic_check']]  # Only using the 'electronic_check' column as a feature\n",
    "y = df['churn']  # Churn is the target variable\n",
    "\n",
    "# 4. Train/Test Split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 5. Logistic Regression Model\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Predictions\n",
    "# Predict churn based on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 7. Evaluate the Model\n",
    "# Print accuracy and other evaluation metrics\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4d05f",
   "metadata": {},
   "source": [
    "#What is the distribution of churn rates across different customer demographics (e.g., age, gender, region)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample Data (you can replace this with your real dataset)\n",
    "data = {\n",
    "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'age': [25, 34, 22, 45, 36, 56, 28, 41, 29, 33],\n",
    "    'gender': ['Male', 'Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Male'],\n",
    "    'region': ['North', 'South', 'East', 'West', 'North', 'East', 'South', 'West', 'North', 'East'],\n",
    "    'churn': [1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
    "}\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Distribution of Churn by Gender\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='gender', hue='churn', palette='Set2')\n",
    "plt.title('Distribution of Churn by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 2. Distribution of Churn by Region\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='region', hue='churn', palette='Set2')\n",
    "plt.title('Distribution of Churn by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 3. Distribution of Churn by Age\n",
    "# For age, we can group the data by age bins to visualize the distribution\n",
    "age_bins = [20, 30, 40, 50, 60, 70]\n",
    "age_labels = ['20-30', '30-40', '40-50', '50-60', '60-70']\n",
    "df['age_group'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='age_group', hue='churn', palette='Set2')\n",
    "plt.title('Distribution of Churn by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 4. Churn Rate by Demographics (Average churn rate for each demographic group)\n",
    "gender_churn_rate = df.groupby('gender')['churn'].mean()\n",
    "region_churn_rate = df.groupby('region')['churn'].mean()\n",
    "age_group_churn_rate = df.groupby('age_group')['churn'].mean()\n",
    "\n",
    "# Display churn rates\n",
    "print(\"\\nChurn Rate by Gender:\")\n",
    "print(gender_churn_rate)\n",
    "\n",
    "print(\"\\nChurn Rate by Region:\")\n",
    "print(region_churn_rate)\n",
    "\n",
    "print(\"\\nChurn Rate by Age Group:\")\n",
    "print(age_group_churn_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954dd1d",
   "metadata": {},
   "source": [
    "### Conclusion for the Exploratory Data Analysis (EDA) Project:\n",
    "\n",
    "In this Exploratory Data Analysis (EDA) project, we have performed an in-depth examination of the dataset to uncover meaningful insights, identify patterns, and assess the underlying structure of the data. The main goals of EDA include understanding the features of the dataset, identifying any data quality issues (like missing values or outliers), and formulating hypotheses for further analysis or modeling.\n",
    "\n",
    "Here are the key takeaways from the EDA process:\n",
    "\n",
    "1. **Data Overview and Structure**:\n",
    "   - We successfully loaded the dataset and examined the first few rows, which helped us understand the types of features available in the dataset (e.g., numerical, categorical).\n",
    "   - We also reviewed the column names, datatypes, and overall dataset dimensions.\n",
    "\n",
    "2. **Handling Missing Values**:\n",
    "   - Through EDA, we identified if any columns had missing values and decided on appropriate strategies for handling them (e.g., imputation, removal).\n",
    "   \n",
    "3. **Statistical Summary**:\n",
    "   - A statistical summary of numerical variables helped to understand the central tendencies (mean, median) and dispersion (standard deviation, quartiles).\n",
    "   - This also allowed us to identify potential outliers or skewed distributions in the data.\n",
    "\n",
    "4. **Univariate Analysis**:\n",
    "   - We performed visualizations like histograms, box plots, and density plots for each variable to analyze their distributions and understand their individual characteristics.\n",
    "   - Categorical variables were analyzed using bar plots to examine their frequency distribution.\n",
    "\n",
    "5. **Bivariate Analysis**:\n",
    "   - We used scatter plots, correlation matrices, and pair plots to explore relationships between numerical variables, which revealed key insights into how variables correlate with each other.\n",
    "   - We also analyzed the relationship between the target variable (e.g., customer churn) and the features to identify trends or patterns that might be useful for predictive modeling.\n",
    "\n",
    "6. **Outlier Detection**:\n",
    "   - Outliers were identified using box plots and statistical measures (such as the IQR method), and their impact on the analysis was considered.\n",
    "   - Appropriate strategies for dealing with outliers were proposed, such as removal or transformation.\n",
    "\n",
    "7. **Feature Engineering and Transformation**:\n",
    "   - Based on insights gained during the analysis, we discussed the possibility of creating new features or transforming existing features (e.g., encoding categorical variables, normalizing numerical features).\n",
    "\n",
    "8. **Data Visualization**:\n",
    "   - We used various visualization techniques (histograms, bar plots, heatmaps, etc.) to represent data insights clearly and make the findings more interpretable.\n",
    "   - Visualizations also helped identify patterns that could inform the next steps in the analysis or modeling phase.\n",
    "\n",
    "9. **Insights for Modeling**:\n",
    "   - We identified potential predictors that could be important for building a predictive model to, for example, forecast customer churn.\n",
    "   - Key insights into data relationships were noted for future machine learning algorithms.\n",
    "\n",
    "### Final Thoughts:\n",
    "The EDA process has allowed us to gain a deep understanding of the dataset, its structure, and its underlying patterns. We now have a clearer picture of the data quality, the relationships between variables, and the most important features for modeling. The insights from this analysis can inform the next steps in data preparation, feature engineering, and building predictive models.\n",
    "\n",
    "The next phase would involve more advanced data preprocessing, feature selection, and model building to develop actionable insights or predictions, depending on the goals of the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
